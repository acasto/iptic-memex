[DEFAULT]
prompt_directory = prompts
chats_directory = sessions
chats_extension = .md
fallback_prompt = You are a helpful assistant that can answer questions.
user_config = ~/.config/iptic-memex/config.ini
default_chat_model = gpt-3.5-turbo
default_completion_model = gpt-3.5-turbo
#temperature = 0.7
#max_tokens = 300
#stream = True
#stream_delay = 0.008
#response_label = AI

[OpenAI]
#api_key =
default = True
completion_models =
completion_endpoint = https://api.openai.com/v1/completions
chat_models = gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-4
chat_endpoint = https://api.openai.com/v1/chat/completions
#temperature = 0.1
#context_window = 4096

[OpenRouter]
#api_key =
chat_models = openai/gpt-4-32k, anthropic/claude-2, google/palm-2-chat-bison, google/palm-2-codechat-bison, meta-llama/llama-2-70b-chat
#context_window = 32000