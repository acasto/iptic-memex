[DEFAULT]
prompt_directory = prompts
chats_directory = sessions
chats_extension = .md
fallback_prompt = You are a helpful assistant that can answer questions.
user_config = ~/.config/iptic-memex/config.ini
user_models = ~/.config/iptic-memex/models.ini
default_model = gpt-4o
#default_prompt = code.txt
#temperature = 0.7
#max_tokens = 500
stream = False
stream_delay = 0.1
user_label = "> User: "
response_label = "> AI: "

## Providers
## Note: Model specific settings are now in models.ini This file is for API keys and other provider level settings.
##       By default all models associated with a provider will be available, but if you wish to restrict access to
##       specific models you can do so by setting the models key to a comma separated list of model names.
##       (Model names are the section names in models.ini, not the full model names from the provider docs)
##
## At minimum you need to set a provider below to active and provide an API key either here or through the environment.

[OpenAI]
#active = True
#api_key =
#organization =
#project =
#models = gpt-3.5-turbo, gpt-4, gpt-4o
endpoint = https://api.openai.com/v1/chat/completions
response_label = "> ChatGPT: "

[Anthropic]
#active = False
#api_key =
endpoint = https://api.anthropic.com/v1/messages
response_label = "> Claude: "

[Google]
#active = False
#api_key =
endpoint = https://api.google.com/v1/chat/completions
response_label = "> Gemini: "
